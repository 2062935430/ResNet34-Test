# ä½¿ç”¨PyTorchå®ç°å›¾åƒåˆ†ç±»
---
## ğŸ¥‡å®šä¹‰æ¨¡å‹ï¼š
  
### ğŸ¥ˆåˆ›å»ºResNetæ–‡ä»¶ï¼Œå»ºç«‹ä¸€ä¸ªå°çš„ç¥ç»ç½‘ç»œ
  
>ä»¥ä¸‹ä¸ºä¸€ä¸ªåŸºäºResNet34æ¨¡å‹çš„å˜ç§ï¼Œå…¶ä¸­å®šä¹‰äº†ä¸€ä¸ªResNet32ç±»ï¼Œ  
>å®ƒåŒ…å«äº†ä¸€ä¸ªå·ç§¯å±‚ï¼Œå››ä¸ªæ®‹å·®å±‚ï¼Œä¸€ä¸ªå¹³å‡æ± åŒ–å±‚å’Œä¸€ä¸ªå…¨è¿æ¥å±‚ï¼Œ  
>æ¯ä¸ªæ®‹å·®å±‚åˆåŒ…å«äº†å¤šä¸ªæ®‹å·®æ¨¡å—ï¼Œæ¯ä¸ªæ®‹å·®æ¨¡å—ç”±ä¸¤ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªå¿«æ·è¿æ¥ç»„æˆã€‚  
  
    import torch
    import torch.nn as nn
    import torch.nn.functional as 


     # æŠŠæ®‹å·®è¿æ¥è¡¥å……åˆ° Block çš„ forward å‡½æ•°ä¸­
     class Block(nn.Module):
        def __init__(self, dim, out_dim, stride) -> None:
            super().__init__()
            self.conv1 = nn.Conv2d(dim, out_dim, kernel_size=3, stride=stride, padding=1)
            self.bn1 = nn.BatchNorm2d(out_dim)
            self.relu1 = nn.ReLU()
            self.conv2 = nn.Conv2d(out_dim, out_dim, kernel_size=3, padding=1)
            self.bn2 = nn.BatchNorm2d(out_dim)
            self.relu2 = nn.ReLU()

            def forward(self, x):
            x = self.conv1(x)
            x = self.bn1(x)
            x = self.relu1(x)
            x = self.conv2(x)
            x = self.bn2(x)
            x = self.relu2(x)
            return x


    class ResNet32(nn.Module):
        def __init__(self, in_channel=64, num_classes=2):
            super().__init__()
            self.num_classes = num_classes
            self.in_channel = in_channel

            self.conv1 = nn.Conv2d(3, self.in_channel, kernel_size=7, stride=2, padding=3)
            self.maxpooling = nn.MaxPool2d(kernel_size=2)
            self.last_channel = in_channel

            self.layer1 = self._make_layer(in_channel=64, num_blocks=3, stride=1)
            self.layer2 = self._make_layer(in_channel=128, num_blocks=4, stride=2)
            self.layer3 = self._make_layer(in_channel=256, num_blocks=6, stride=2)
            self.layer4 = self._make_layer(in_channel=512, num_blocks=3, stride=2)

            self.avgpooling = nn.AvgPool2d(kernel_size=2)
            self.classifier = nn.Linear(4608, self.num_classes)

        def _make_layer(self, in_channel, num_blocks, stride):
            layer_list = [Block(self.last_channel, in_channel, stride)]
            self.last_channel = in_channel
            for i in range(1, num_blocks):
                b = Block(in_channel, in_channel, stride=1)
                layer_list.append(b)
            return nn.Sequential(*layer_list)

        def forward(self, x):
            x = self.conv1(x)  # [bs, 64, 56, 56] ç‰¹å¾æå–è¿‡ç¨‹
            x = self.maxpooling(x)  # [bs, 64, 28, 28]æ± åŒ–ï¼Œé™ä½åˆ†è¾¨ç‡å’Œè®¡ç®—é‡
            x = self.layer1(x)
            x = self.layer2(x)
            x = self.layer3(x)
            x = self.layer4(x)
            x = self.avgpooling(x)
            x = x.view(x.shape[0], -1)
            x = self.classifier(x)
            output = F.softmax(x,dim=1) # è®¾ç½®dim = 1ï¼Œå¯¹å›¾åƒæ²¿ç€æŸç»´åº¦è¿›è¡Œå½’ä¸€åŒ–ï¼Œå¾—åˆ°æ¯å¼ å›¾ç‰‡çš„æ¦‚ç‡åˆ†å¸ƒæˆ–é¢„æµ‹ç±»åˆ«

            return output


    if __name__=='__main__':
        t = torch.randn([8, 3, 224, 224])
        model = ResNet32()
        out = model(t)
        print(out.shape)
        
        
åœ¨å‘½ä»¤è¡Œè°ƒç”¨è¯¥æ¨¡å‹ï¼Œæ˜¾ç¤ºç»“æœä¸ºï¼š
  
![ResNetç»“æœ](https://github.com/2062935430/ResNet34-Test/assets/128795948/bc8ac95a-58e7-40b8-a1d7-0bed798da981)  
  
ç”±æ­¤å¯ä»¥çœ‹å‡ºè¯¥æ¨¡å‹çš„è¾“å…¥å¼ é‡æ˜¯ä¸€ä¸ª8x3x224x224çš„å¼ é‡ï¼Œ  
è¡¨ç¤ºæœ‰8ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰3ä¸ªé€šé“ï¼Œæ¯ä¸ªé€šé“æœ‰224x224ä¸ªåƒç´ ã€‚  

è¯¥æ¨¡å‹çš„è¾“å‡ºå¼ é‡æ˜¯ä¸€ä¸ª8x2çš„å¼ é‡ï¼Œ  
è¡¨ç¤ºæœ‰8ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æœ‰2ä¸ªç±»åˆ«çš„æ¦‚ç‡ï¼Œ  
è¿™æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒäºŒåˆ†ç±»ä»»åŠ¡çš„ç¥ç»ç½‘ç»œæ¨¡å‹  
  
## ğŸ¥‡å›¾åƒåˆ†ç±»æ¨¡å‹çš„è®­ç»ƒå’Œæµ‹è¯•
  
### ğŸ¥ˆè®­ç»ƒè¿‡ç¨‹(train)ï¼š
  
>ğŸ¥‰**éªŒè¯é›†valä¸æµ‹è¯•é›†test**  
>  
>ç›¸åŒç‚¹:  
>å®ƒä»¬éƒ½ä¸å‚ä¸æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œåªç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚  
>å®ƒä»¬éƒ½éœ€è¦å’Œè®­ç»ƒé›†æœ‰è¿‘ä¼¼çš„æ•°æ®åˆ†å¸ƒï¼Œä»¥ä¿è¯æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚  
>  
>ä¸åŒç‚¹:   
>éªŒè¯é›†ç”¨äºè¿›ä¸€æ­¥ç¡®å®šæ¨¡å‹ä¸­çš„è¶…å‚æ•°ï¼ˆä¾‹å¦‚æ­£åˆ™é¡¹ç³»æ•°ã€ANNä¸­éšå«å±‚çš„èŠ‚ç‚¹ä¸ªæ•°ç­‰ï¼‰ï¼Œä¸»è¦ç›®çš„æ˜¯ä¸ºäº†æŒ‘é€‰åœ¨éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ¨¡å‹ã€‚  
>æµ‹è¯•é›†åªæ˜¯ç”¨äºè¯„ä¼°æ¨¡å‹çš„ç²¾ç¡®åº¦ï¼ˆå³æ³›åŒ–èƒ½åŠ›ï¼‰ï¼Œä¸»è¦ç›®çš„æ˜¯ä¸ºäº†çœ‹çœ‹æ¨¡å‹åœ¨å®é™…ç”Ÿæ´»ä¸­å¦‚ä½•å¤„ç†ã€‚  
>éªŒè¯é›†æ˜¯ç”¨æ¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­ä¼˜åŒ–æ¨¡å‹çš„ï¼Œè€Œæµ‹è¯•é›†æ˜¯ç”¨æ¥åœ¨è®­ç»ƒç»“æŸåæœ€ç»ˆè¯„ä»·æ¨¡å‹çš„ã€‚  
>  
>ç›®çš„ï¼š  
>éªŒè¯é›†æ˜¯ç”¨æ¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°æ¨¡å‹çš„æ•ˆæœå’Œè°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°çš„æ•°æ®æ ·æœ¬ã€‚  
>ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨éªŒè¯é›†æ¥é€‰æ‹©æœ€ä¼˜çš„å­¦ä¹ ç‡ã€è¿­ä»£æ¬¡æ•°ã€å±‚æ•°ç­‰ã€‚   
>   
>æµ‹è¯•é›†æ˜¯ç”¨æ¥åœ¨è®­ç»ƒç»“æŸåè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å’Œåˆ†ç±»èƒ½åŠ›çš„æ•°æ®æ ·æœ¬ã€‚  
>ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨æµ‹è¯•é›†æ¥ä¼°è®¡æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„æ³›åŒ–è¯¯å·®ã€‚  
>  
>éªŒè¯é›†å’Œæµ‹è¯•é›†éƒ½ä¸å‚ä¸æ¨¡å‹çš„æ‹Ÿåˆï¼Œä½†éªŒè¯é›†ä¼šå½±å“æ¨¡å‹çš„é€‰æ‹©ï¼Œè€Œæµ‹è¯•é›†ä¸ä¼š  
  
>ğŸ¥‰**è¶…å‚æ•°**  
>  
>è¶…å‚æ•°çš„ä¼˜åŒ–æ˜¯æœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªé‡è¦çš„æ­¥éª¤ï¼Œéœ€è¦é€šè¿‡ä¸åŒçš„ç­–ç•¥æ¥æœç´¢æœ€ä½³çš„é…ç½®ï¼Œä¾‹å¦‚ç½‘æ ¼æœç´¢ã€éšæœºæœç´¢ã€è´å¶æ–¯ä¼˜åŒ–ç­‰ã€‚   
>   
>ç¬¼ç»Ÿè€Œè¨€ï¼Œå¦‚æœæŠŠè®­ç»ƒè¿‡ç¨‹æ¯”å–»ä¸ºåšè›‹ç³•ï¼Œé‚£æˆ‘ä»¬ä¼šéœ€è¦ç”¨åˆ°ä¸€äº›ææ–™ï¼Œæ¯”å¦‚é¢ç²‰ã€é¸¡è›‹ã€ç‰›å¥¶ã€ç³–ç­‰ã€‚  
>è¿™äº›ææ–™å°±ç›¸å½“äºæ¨¡å‹å‚æ•°ï¼Œå®ƒä»¬æ˜¯éœ€è¦ç”¨æ•°æ®æ¥ä¼°è®¡çš„ï¼Œä¹Ÿå°±æ˜¯éœ€è¦æ ¹æ®ä¸åŒçš„è›‹ç³•é£Ÿè°±æ¥ç¡®å®šå…¶æ¯”ä¾‹å’Œæ•°é‡ã€‚  
>    
>ä½†æˆ‘ä»¬è¿˜éœ€è¦ä¸€äº›å…¶ä»–çš„ä¸œè¥¿ï¼Œ  
>æ¯”å¦‚çƒ¤ç®±çš„æ¸©åº¦ã€çƒ˜ç„™çš„æ—¶é—´ã€è›‹ç³•çš„å¤§å°å’Œå½¢çŠ¶ç­‰ç­‰ã€‚ 
>è¿™äº›ä¸œè¥¿å°±ç›¸å½“äºè¶…å‚æ•°ï¼Œå®ƒä»¬æ˜¯ä½ éœ€è¦äººä¸ºè®¾å®šçš„ï¼Œä¹Ÿå°±æ˜¯éœ€è¦æ ¹æ®è‡ªèº«ç»éªŒä¸å°è¯•æ¥é€‰æ‹©åˆé€‚çš„å€¼ã€‚  
>è¶…å‚æ•°çš„ä¼˜åŒ–å°±æ˜¯ä¸ºäº†æ‰¾åˆ°æœ€é€‚åˆåšè›‹ç³•çš„æ¸©åº¦ã€æ—¶é—´ã€å¤§å°å’Œå½¢çŠ¶ç­‰ç­‰ã€‚  
  
    import argparse
    import time
    import json
    import os
    import ResNet34

    from tqdm import tqdm
    from models import *
    # from efficientnet_pytorch import EfficientNet
    from torch import nn
    from torch import optim
    # from torch.optim.lr_scheduler import *
    from torchvision import transforms
    from torchvision import datasets
    from torch.utils.data import DataLoader
    from tools import warmup_lr


    # åˆå§‹åŒ–å‚æ•°
    def get_args():
        """åœ¨ä¸‹é¢åˆå§‹åŒ–ä½ çš„å‚æ•°.
        """
        parser = argparse.ArgumentParser(description='åŸºäºPytorchå®ç°çš„åˆ†ç±»ä»»åŠ¡')

        # exp
        parser.add_argument('--time_exp_start', type=str,
                        default=time.strftime('%m-%d-%H-%M', time.localtime(time.time())))
        parser.add_argument('--train_dir', type=str, default='data/train')
        parser.add_argument('--val_dir', type=str, default='data/val')
        parser.add_argument('--epochs', type=int, default=5)
        parser.add_argument('--save_station', type=int, default=1)
        parser.add_argument('--num_workers', type=int, default=4)
        parser.add_argument('--is_mps', type=bool, default=False)
        parser.add_argument('--is_cuda', type=bool, default=False)
        parser.add_argument('--batch_size', type=int, default=4)
        parser.add_argument('--test_batch_size', type=int, default=4)
        parser.add_argument('--lr', type=float, default=0.001)

        # dataset
        parser.add_argument('--num_classes', type=int, default=2)
        parser.add_argument('--data_mean', type=tuple, default=[.5, .5, .5])
        parser.add_argument('--data_std', type=tuple, default=[.5, .5, .5])

        # model
        parser.add_argument('--model', type=str, default='ResNet18',
                            choices=[
                                'ResNet18',
                                'ResNet34',
                                'ResNet50',
                                'ResNet18RandomEncoder',
                            ])

        # scheduler
        parser.add_argument('--warmup_epoch', type=int, default=1)

        # é€šè¿‡jsonè®°å½•å‚æ•°é…ç½®
        args = parser.parse_args()
        args.directory = 'dictionary/%s/Hi%s/' % (args.model, args.time_exp_start)
        log_file = os.path.join(args.directory, 'log.json')
        if not os.path.exists(args.directory):
            os.makedirs(args.directory)
        with open(log_file, 'w') as log:
            json.dump(vars(args), log, indent=4)

        # è¿”å›å‚æ•°é›†
        return args


    class Worker:
        def __init__(self, args):
            self.opt = args

            # åˆ¤å®šè®¾å¤‡
            self.device = torch.device('cuda:0' if args.is_cuda else 'cpu')
            kwargs = {
                'num_workers': args.num_workers,
                'pin_memory': True,
            } if args.is_cuda else {}

            # è½½å…¥æ•°æ®
            train_dataset = datasets.ImageFolder(
                args.train_dir,
                transform=transforms.Compose([
                    transforms.RandomResizedCrop(256),
                    transforms.ToTensor()
                    # transforms.Normalize(opt.data_mean, opt.data_std)
                ])
            )
            val_dataset = datasets.ImageFolder(
                args.val_dir,
                transform=transforms.Compose([
                    transforms.RandomResizedCrop(256),
                    transforms.ToTensor()
                    # transforms.Normalize(opt.data_mean, opt.data_std)
                ])
            )
            self.train_loader = DataLoader(
                dataset=train_dataset,
                batch_size=args.batch_size,
                shuffle=True,
                **kwargs
            )
            self.val_loader = DataLoader(
                dataset=val_dataset,
                batch_size=args.test_batch_size,
                shuffle=False,
                **kwargs
            )

            # æŒ‘é€‰ç¥ç»ç½‘ç»œã€å‚æ•°åˆå§‹åŒ–
            net = None
            if args.model == 'ResNet18':
                net = ResNet18(num_cls=args.num_classes)
            elif args.model == 'ResNet34':
                net = ResNet34(num_cls=args.num_classes)
            elif args.model == 'ResNet50':
                net = ResNet50(num_cls=args.num_classes)
            elif args.model == 'ResNet18RandomEncoder':
                net = ResNet18RandomEncoder(num_cls=args.num_classes)
            assert net is not None

            self.model = net.to(self.device)

            # ä¼˜åŒ–å™¨
            self.optimizer = optim.AdamW(
                self.model.parameters(),
                lr=args.lr
            )

            # æŸå¤±å‡½æ•°
            self.loss_function = nn.CrossEntropyLoss()

            # warm up å­¦ä¹ ç‡è°ƒæ•´éƒ¨åˆ†
            self.per_epoch_size = len(train_dataset) // args.batch_size
            self.warmup_step = args.warmup_epoch * self.per_epoch_size
            self.max_iter = args.epochs * self.per_epoch_size
            self.global_step = 0

    def train(self, epoch):
            self.model.train()
            bar = tqdm(enumerate(self.train_loader))
            for batch_idx, (data, target) in bar:
                self.global_step += 1
                data, target = data.to(self.device), target.to(self.device)

                # è®­ç»ƒä¸­...
                self.optimizer.zero_grad()
                output = self.model(data)
                loss = self.loss_function(output, target)
                loss.backward()
                self.optimizer.step()
                lr = warmup_lr.adjust_learning_rate_cosine(
                    self.optimizer, global_step=self.global_step,
                    learning_rate_base=self.opt.lr,
                    total_steps=self.max_iter,
                    warmup_steps=self.warmup_step
                )

                # æ›´æ–°è¿›åº¦æ¡
                bar.set_description(
                    'train epoch {} >> [{}/{} ({:.0f}%)]\tLoss: {:.6f}\tlr: {:.6f} >> '.format(
                        epoch,
                        batch_idx * len(data),
                        len(self.train_loader.dataset),
                        100. * batch_idx / len(self.train_loader),
                        loss.item(),
                        lr
                    )
                )
            bar.close()

        def val(self):
            self.model.eval()
            validating_loss = 0
            num_correct = 0
            with torch.no_grad():
                bar = tqdm(self.val_loader)
                for data, target in bar:
                    # æµ‹è¯•ä¸­...
                    data, target = data.to(self.device), target.to(self.device)
                    output = self.model(data)
                    validating_loss += self.loss_function(output, target).item()  # ç´¯åŠ  batch loss
                    pred = output.argmax(dim=1, keepdim=True)  # è·å–æœ€å¤§æ¦‚ç‡ç¥ç»å…ƒä¸‹æ ‡
                    num_correct += pred.eq(target.view_as(pred)).sum().item()
                bar.close()

            # æ‰“å°éªŒè¯ç»“æœ
            validating_loss /= len(self.val_loader)
            print('val >> Average loss: {:.4f}, Accuracy: {}/{} ({:.03f}%)\n'.format(
                validating_loss,
            num_correct,
            len(self.val_loader.dataset),
            100. * num_correct / len(self.val_loader.dataset))
            )

            # è¿”å›é‡è¦ä¿¡æ¯ï¼Œç”¨äºç”Ÿæˆæ¨¡å‹ä¿å­˜å‘½å
            return 100. * num_correct / len(self.val_loader.dataset), validating_loss


    if __name__ == '__main__':
        # åˆå§‹åŒ–
        torch.backends.cudnn.benchmark = True
        torch.cuda.manual_seed(0)
        args = get_args()
        worker = Worker(args=args)

        # è®­ç»ƒä¸éªŒè¯
        for epoch in range(1, args.epochs + 1):
            worker.train(epoch)
            val_acc, val_loss = worker.val()
            if epoch > args.save_station:
                save_dir = args.directory + '%s-epochs-%d-model-val-acc-%.3f-loss-%.6f.pt' \
                           % (args.model, epoch, val_acc, val_loss)
                torch.save(worker.model, save_dir)
                
åœ¨ä»¥ä¸Šä»£ç importè¿›äº†å’Œtrainæ–‡ä»¶åŒä¸€ç›®å½•ä¸‹çš„ResBet34æ¨¡å‹ï¼Œ  
æ‰€ä»¥æˆ‘ä»¬ç›´æ¥è¿›å…¥å‘½ä»¤è¡Œè°ƒç”¨train.pyæ–‡ä»¶è¿›è¡Œæ¨¡å‹è®­ç»ƒæ—¶ï¼Œ  
è¯¥è®­ç»ƒä¼šé»˜è®¤ä½¿ç”¨åŒä¸€ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶å±•å¼€å›¾åƒåˆ†ç±»çš„è®­ç»ƒè¿‡ç¨‹ï¼Œ  
ç»“æœå¦‚ä¸‹ï¼š  
  
![ä½¿ç”¨ResNet34æ¨¡å‹å®Œæˆtrain](https://github.com/2062935430/ResNet34-Test/assets/128795948/77384b99-e2a6-45fa-8cf4-4f88cdb99a13)
  
### ğŸ¥ˆæµ‹è¯•è¿‡ç¨‹ï¼ˆtestï¼‰ï¼š  
